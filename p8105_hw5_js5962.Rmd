---
title: "p8105_hw5_js5962"
output: github_document
---

```{r setup,echo = FALSE, message = FALSE}
library(tidyverse)

theme_set(theme_minimal() + theme(legend.position = "bottom"))
knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = 0.6,
  out.width = "90%"
)

options(
  ggplot2.continuous.color = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_color_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```


## Problem 1


a) Import the data and clean.

```{r import_data}
homicide_df =
  read.csv("homicide-data.csv", na = c("", "Unknown")) 
```

Describe the raw data: The dataset homicide_data is collected by _The Washington Post_ on homicides in 50 large U.S. cities. The data contains `r nrow(homicide_df)` rows and `r ncol(homicide_df)` columns. Each row represents one case. Variables describe the report data, location, victim's information and disposition od the cases.

```{r dataclean}
homicide_clean =
  homicide_df %>% 
  mutate(city_state = str_c(city, ",", state),#create variable
         result = case_when(
           disposition == "Closed without arrest" ~ "unsolved",
           disposition == "Open/No arrest" ~ "unsolved",
           disposition == "Closed by arrest" ~ "solved"
         )) %>% 
  relocate(city_state) %>% 
  filter(city_state != "Tulsa,AL") 
homicide_clean %>% 
  select(-city, -state) %>% #summarize numbers
  group_by(city_state) %>% 
  summarize(unsolved = sum(result == "unsolved"),#summarize numbers
            n = n()) %>% 
  knitr::kable()
```

b) use the prop.test function to estimate the proportion of homicides that are unsolved in the city of Baltimore, MD.

```{r blatimore}
baltimore_df = homicide_clean %>% 
  filter(city_state == "Baltimore,MD")

baltimore_unsolved =     
  baltimore_df %>% 
  summarize(unsolved = sum(result == "unsolved"),
            n = n())
baltimore_prop =
  prop.test(x = baltimore_unsolved %>% pull(unsolved), 
          n = baltimore_unsolved %>% pull(n))
tidy_df = baltimore_prop %>% 
  broom::tidy()
tidy_df
# pull the estimated proportion and confidence intervals from the resulting tidy dataframe
tidy_df %>% 
  select(estimate, conf.low, conf.high)
```

c) Run prop.test for each of the cities in your dataset, and extract both the proportion of unsolved homicides and the confidence interval for each.

Firstly build the function.

```{r prop_function}
prop_test = function(city_df){
  
  city_unsolved =     
  city_df %>% 
  summarize(unsolved = sum(result == "unsolved"),
            n = n())
  
city_prop =
  prop.test(x = baltimore_unsolved %>% pull(unsolved), 
          n = baltimore_unsolved %>% pull(n))
return(city_prop)
}
```

We iterate by mapping.

```{r iterate_city, warning = FALSE}
result_df =
  homicide_clean %>% 
  nest(data = uid:result) %>% 
  mutate(
    test_result = purrr::map(data, prop_test),
    tidy_result = purrr::map(test_result, broom::tidy)
  ) %>% 
  select(-test_result) %>% 
  unnest(tidy_result) %>% 
  select(city_state, estimate, conf.low, conf.high)
show(result_df)
```

use map2.

```{r second_method}
result_df2 =
  homicide_clean %>% 
  select(-city, -state) %>% 
  group_by(city_state) %>% 
  summarize(unsolved = sum(result == "unsolved"),
            n = n()) %>% 
  mutate(
    test_result = purrr::map2(unsolved, n, prop.test),
    tidy_result = purrr::map(test_result, broom::tidy)
  ) %>% 
  select(-test_result) %>% 
  unnest(tidy_result) %>% 
  select(city_state, estimate, conf.low, conf.high)
show(result_df2)
```

d) Create a plot that shows the estimates and CIs for each city.

```{r bar_plot}
result_df %>% 
  mutate(
    city_state = fct_reorder(city_state, estimate)
    ) %>% 
   ggplot(aes(x = city_state, y = estimate)) +
   geom_point() +
   geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
   theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
   labs(title = "Unsolved crime proportion and confidence interval in cities") +
  theme(plot.title = element_text(hjust = 0.5))
```

## Problem 2

Start with a dataframe containing all file names; the list.files function will help

```{r list}
longi_df = tibble(
  file_name = list.files("longitudinal study")
)
```

Now build a read data function

```{r read_data}
read_data = function(name) {
  path = str_c("./longitudinal study/", name)
  data = read.csv(path)
  return(data)
}
```

Iterate over file names and read in data for each subject using purrr::map and saving the result as a new variable in the dataframe

```{r map_into_df}
new_df = longi_df %>% 
  mutate(
    newlist = purrr::map(.x = as.character(file_name), ~read_data(.x))
    ) %>% 
  unnest(newlist) %>% 
#Tidy the result
  mutate(
    subject_id = substr(file_name, 1, 6),
    arm = substr(file_name, 1, 3)
  ) %>% 
  select(-file_name) %>% 
  relocate(subject_id, arm) %>% 
  janitor::clean_names() %>% 
  drop_na() %>% 
  pivot_longer(
    cols = week_1:week_8,
    names_to = "week",
    values_to = "value"
  ) %>% 
  mutate(week = substr(week, 6, 6))
```

Make a spaghetti plot showing observations on each subject over time, and comment on differences between groups.

```{r spaghetti, fig.width=9, message=FALSE, warning=FALSE}
new_df %>% 
  ggplot(aes(x = as.numeric(week), y = value, color = as.factor(subject_id))) +
  geom_line() + geom_point(aes(shape = as.factor(arm)), alpha = 0.7) +
  labs(title = "Obervation over weeks", x = "weeks", y = "value") +
  scale_colour_hue("Subject_id") +
  scale_shape("Arm") +
  theme(plot.title = element_text(hjust = 0.5))
```

comment: observations show that the experiment groups increase much more than the control groups over time.

## Problem 3

```{r given}
library(tidyverse)

set.seed(10)

iris_with_missing = iris %>% 
  map_df(~replace(.x, sample(1:150, 20), NA)) %>%
  mutate(Species = as.character(Species))
```

refill missing data function

```{r refill_missing}
refill_miss = function(miss) {

# For numeric variables
  if (is.numeric(miss)) {
    mean_miss = round(mean(miss, na.rm = TRUE), digits = 3)
    miss = replace_na(miss, mean_miss)
  }

# For character variables
  if (is.character(miss)) {
    miss = replace_na(miss, "virginica")
  }
  return(miss)
}
```

Then Refill and Build the new data

```{r refill_data}
iris_new = map(iris_with_missing, refill_miss) %>% 
  bind_cols()
iris_new
```


